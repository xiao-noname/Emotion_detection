{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLwNaDcZ67su",
    "outputId": "cd401125-b517-47fe-ee8d-811df55be3b6"
   },
   "outputs": [],
   "source": [
    "#IMPORT THE LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import tensorflow as tf\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHdMhC6qMFJt",
    "outputId": "1464d3f9-d892-45ed-d849-795e72a91209"
   },
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8qlntWasYEe"
   },
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lmOpneJsbni"
   },
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGQ_zXJlscE2"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TA7XU3chtKHI",
    "outputId": "a13a3311-94bb-479f-ad07-76d9d29a0e5d"
   },
   "outputs": [],
   "source": [
    "! kaggle datasets download -d mostafaabdlhamed/speech-signal-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icZCjFmtt1S4",
    "outputId": "c04c046f-7b5a-432d-d332-e511c5447dd3"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "# Replace 'your_file.zip' with the path to your ZIP file\n",
    "zip_path = '/content/speech-signal-features.zip'\n",
    "extract_to = '/content'\n",
    "\n",
    "# Create a directory to extract to if it doesn't exist\n",
    "if not os.path.exists(extract_to):\n",
    "    os.makedirs(extract_to)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n",
    "\n",
    "print(f'Files extracted to {extract_to}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ad3hEY2UC8eM"
   },
   "outputs": [],
   "source": [
    "ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "ravdess_directory_list = os.listdir(ravdess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwkPt_XEC8as"
   },
   "outputs": [],
   "source": [
    "Crema = \"/kaggle/input/cremad/AudioWAV/\"\n",
    "Tess = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
    "Savee = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9qBAnYYC8Yd"
   },
   "outputs": [],
   "source": [
    "file_emotion = []\n",
    "file_path = []\n",
    "for i in ravdess_directory_list:\n",
    "    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n",
    "    actor = os.listdir(ravdess + i)\n",
    "    for f in actor:\n",
    "        part = f.split('.')[0].split('-')\n",
    "    # third part in each file represents the emotion associated to that file.\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(ravdess + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8zFiCXIC8Vl"
   },
   "outputs": [],
   "source": [
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "# changing integers to actual emotions.\n",
    "ravdess_df.Emotions.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust',\n",
    "                             8:'surprise'},\n",
    "                            inplace=True)\n",
    "print(ravdess_df.head())\n",
    "print(\"______________________________________________\")\n",
    "print(ravdess_df.tail())\n",
    "print(\"_______________________________________________\")\n",
    "print(ravdess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HA6EDs1C8S_"
   },
   "outputs": [],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    # storing file paths\n",
    "    file_path.append(Crema + file)\n",
    "    # storing file emotions\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()\n",
    "print(Crema_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJlvrOhqC8PP"
   },
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()\n",
    "print(Tess_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTh2JANRC8Mv"
   },
   "outputs": [],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()\n",
    "print(Savee_df.Emotions.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhfChijaC8Js"
   },
   "outputs": [],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = pd.concat([ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bhtijbxC8HL"
   },
   "outputs": [],
   "source": [
    "data,sr = librosa.load(file_path[0])\n",
    "sr\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaaUa-NGC8D0"
   },
   "outputs": [],
   "source": [
    "# CREATE LOG MEL SPECTROGRAM\n",
    "plt.figure(figsize=(10, 5))\n",
    "spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000)\n",
    "log_spectrogram = librosa.power_to_db(spectrogram)\n",
    "librosa.display.specshow(log_spectrogram, y_axis='mel', sr=sr, x_axis='time');\n",
    "plt.title('Mel Spectrogram ')\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIy1VIlIC8BI"
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)\n",
    "\n",
    "\n",
    "# MFCC\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_yIkJG29C7-C"
   },
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "# STRETCH\n",
    "def stretch(data, rate=0.8):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "# SHIFT\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
    "    return np.roll(data, shift_range)\n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6qw8ak4C76l"
   },
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "\n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result\n",
    "\n",
    "def get_features(path,duration=2.5, offset=0.6):\n",
    "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
    "    aud=extract_features(data)\n",
    "    audio=np.array(aud)\n",
    "\n",
    "    noised_audio=noise(data)\n",
    "    aud2=extract_features(noised_audio)\n",
    "    audio=np.vstack((audio,aud2))\n",
    "\n",
    "    pitched_audio=pitch(data,sr)\n",
    "    aud3=extract_features(pitched_audio)\n",
    "    audio=np.vstack((audio,aud3))\n",
    "\n",
    "    pitched_audio1=pitch(data,sr)\n",
    "    pitched_noised_audio=noise(pitched_audio1)\n",
    "    aud4=extract_features(pitched_noised_audio)\n",
    "    audio=np.vstack((audio,aud4))\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vI6s2CwC73j"
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtwEddFRC7xL"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "from tqdm import tqdm\n",
    "start = timeit.default_timer()\n",
    "X,Y=[],[]\n",
    "for path,emotion,index in tqdm (zip(data_path.Path,data_path.Emotions,range(data_path.Path.shape[0]))):\n",
    "    features=get_features(path)\n",
    "    if index%500==0:\n",
    "        print(f'{index} audio has been processed')\n",
    "    for i in features:\n",
    "        X.append(i)\n",
    "        Y.append(emotion)\n",
    "print('Done')\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9RSllSqC7nZ"
   },
   "outputs": [],
   "source": [
    "Emotions = pd.DataFrame(X)\n",
    "Emotions['Emotions'] = Y\n",
    "Emotions.to_csv('emotion.csv', index=False)\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "Ts-h7_bmMEge",
    "outputId": "473686d8-f2a6-41c8-a654-2cf98880aa8e"
   },
   "outputs": [],
   "source": [
    "Emotions = pd.read_csv('/content/emotion.csv')\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAsjDuCi5gWh",
    "outputId": "c4fc0567-1daa-477f-c79e-45756b3d05b8"
   },
   "outputs": [],
   "source": [
    "print(Emotions.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoylWE3XKfJX",
    "outputId": "4ba21228-8460-4473-81f0-187307383dec"
   },
   "outputs": [],
   "source": [
    "Emotions=Emotions.fillna(0)\n",
    "print(Emotions.isna().any())\n",
    "Emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYUxvXkPKfL3",
    "outputId": "63a03a1c-8401-448b-f463-54fa7203e528"
   },
   "outputs": [],
   "source": [
    "np.sum(Emotions.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpCPDRYCKfOV"
   },
   "outputs": [],
   "source": [
    "#taking all rows and all cols without last col for X which include features\n",
    "#taking last col for Y, which include the emotions\n",
    "\n",
    "\n",
    "X = Emotions.iloc[: ,:-1].values\n",
    "Y = Emotions['Emotions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NolWEAMKfQ_"
   },
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H85PrtMqKfTd",
    "outputId": "876be0c6-7878-4f3c-e57c-bfa1eb81bbcb"
   },
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SRA4-yiNB4U",
    "outputId": "4c355929-372f-44f1-9b88-6743bfd16c3c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=42,test_size=0.2, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOBjWVX9NB8A"
   },
   "outputs": [],
   "source": [
    "#reshape for lstm\n",
    "X_train = x_train.reshape(x_train.shape[0] , x_train.shape[1] , 1)\n",
    "X_test = x_test.reshape(x_test.shape[0] , x_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auxp20wxNB_1",
    "outputId": "e89001c1-198e-414c-8881-7dfb0040a3a5"
   },
   "outputs": [],
   "source": [
    "# scaling our data with sklearn's Standard scaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN+LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0s-o6vpNCCU"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahiK99BkNMwC"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "model_checkpoint = ModelCheckpoint('best_model1_weights.h5', monitor='val_accuracy', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL9PuBQ8NM7h"
   },
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(monitor='val_accuracy',mode='auto',patience=5,restore_best_weights=True)\n",
    "lr_reduction=ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tz6gc1BNM_j",
    "outputId": "42c71b4d-1622-4dbc-d3a0-f682764acb77"
   },
   "outputs": [],
   "source": [
    "#Reshape for CNN_LSTM MODEL\n",
    "\n",
    "x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape\n",
    "#x_testcnn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoqPmyD8NhZH",
    "outputId": "9eb44b37-1cb6-4ea3-dc96-91294e3dfdd3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPool1D, Dropout, Flatten, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_traincnn.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "\n",
    "    Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "\n",
    "    Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(pool_size=5, strides=2, padding='same'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool1D(pool_size=3, strides=2, padding='same'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # LSTM Layer\n",
    "    # Note: Return_sequences is set to True if you are adding additional LSTM layers\n",
    "    LSTM(128, return_sequences=False),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(7, activation='softmax')  # Assuming 7 classes for your problem\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYvxTLMVNhfQ",
    "outputId": "a82e8d37-7876-4cb2-cde8-dffdc31a184c"
   },
   "outputs": [],
   "source": [
    "history=model.fit(x_traincnn, y_train, epochs=50, validation_data=(x_testcnn, y_test), batch_size=64,callbacks=[early_stop,lr_reduction,model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "FV4YJAesNhiX",
    "outputId": "dcf238c3-e45f-4603-a442-ad5db907a933"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(50)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "BNuVLXmu65V-",
    "outputId": "4107cbf1-1901-4cbe-9780-da1e10ee5228"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(x_testcnn,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(30)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "6H-YDgYk8dY-",
    "outputId": "ed1d3f30-f53a-48f8-a51e-cc8885ed042f"
   },
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test0 = model.predict(x_testcnn)\n",
    "y_pred0 = encoder.inverse_transform(pred_test0)\n",
    "y_test0 = encoder.inverse_transform(y_test)\n",
    "\n",
    "# Check for random predictions\n",
    "df0 = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df0['Predicted Labels'] = y_pred0.flatten()\n",
    "df0['Actual Labels'] = y_test0.flatten()\n",
    "\n",
    "df0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "gWPXOwyS8XUT",
    "outputId": "1b48a8e4-ec8b-40db-d200-cea34240502e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your model\n",
    "model = load_model('/content/best_model1_weights.h5')\n",
    "\n",
    "# Evaluate on training data\n",
    "train_loss, train_accuracy = model.evaluate(x_traincnn, y_train)\n",
    "\n",
    "# Evaluate on testing data\n",
    "test_loss, test_accuracy = model.evaluate(x_testcnn, y_test)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Training Accuracy: {train_accuracy * 100}%\")\n",
    "print(f\"Testing Loss: {test_loss}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100}%\")\n",
    "\n",
    "# Visualize the metrics\n",
    "metrics = ['Loss', 'Accuracy']\n",
    "train_metrics = [train_loss, train_accuracy]\n",
    "test_metrics = [test_loss, test_accuracy]\n",
    "\n",
    "x = range(len(metrics))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, train_metrics, width=0.4, label='Train', align='center')\n",
    "plt.bar([p + 0.4 for p in x], test_metrics, width=0.4, label='Test', align='center')\n",
    "plt.xticks([p + 0.2 for p in x], metrics)\n",
    "plt.title('Training vs Testing Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
